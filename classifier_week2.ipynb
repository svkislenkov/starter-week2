{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have new and improved documentation at:\n",
    "\n",
    "https://docs.google.com/document/d/1Nbtx1lg2J6yfMFdQdcewOzdcUaUSZ7qScDBjyGNJVQE/edit?usp=sharing\n",
    "\n",
    "^^^ Do all of this stuff first before proceeding here! ^^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The first time you do this in Visual Studio Code, it may ask you which Python environment to use. Select the one you previously initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "# This was in a tutorial. Not sure if it's really necessary but run just in case..\n",
    "\n",
    "## IMPORTANT: If you are on Windows, uncomment this line: ##\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shows us which GPUs our system has access to. It's okay if you don't have any.\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Check out our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Change 'data' to the name of your training set directory\n",
    "# You should see a list of classes\n",
    "data_dir = 'data'\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This formats our data...\n",
    "# TODO: Ensure the image size is kept at (100, 100)\n",
    "data = tf.keras.utils.image_dataset_from_directory(data_dir, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each time we call this, it gives us a new set of data\n",
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 32 images per batch, 100x100, 3 channels (R, G, B)\n",
    "batch = data_iterator.next()\n",
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Scale Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Our tensorflow model works with values between 0 and 1.\n",
    "2. Our images give us pixel R, G, B values from 0-255.\n",
    "\n",
    "Thus, we need to scale our input data down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Pixel values range from 0-255. We want to scale x to range between 0-1.\n",
    "# x represents our data, and y represents our class. Therefore, we shouldn't worry about y\n",
    "\n",
    "# TODO: Uncomment + complete the following statement:\n",
    "# data = data.map(lambda x,y: (x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will now give us an iterator with our SCALED data!\n",
    "scaled_iterator = data.as_numpy_iterator()\n",
    "batch = scaled_iterator.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once previous TODOs are complete, you should see 4 100x100 images here (of fruits, hopefully)\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Include Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Now, it's your turn. Using the '+ Code' button, complete the same steps. Except this time, with the testing directory...\n",
    "\n",
    "**Note: for functionality, you'll only need to pattern-match some of the lines.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Create Validation Set\n",
    "\n",
    "Steal from our training set to form our validation set. This is not usually optimal, but should work for our purposes, especially since we've now shuffled our data when we pull from our Fruits Training directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.7)\n",
    "val_size = int(len(data) * 0.3)\n",
    "# Leave our test data alone\n",
    "\n",
    "# TODO: put in the name of your test_data here\n",
    "test_size = int(len(test_data))\n",
    "\n",
    "# TODO: Make sure train_size + val_size + test_size lines up with the total size of your data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how we separate the training + validation data...\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = test_data.take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Build Deep Learning Model\n",
    "(We will get into this more the second week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add in all your layers here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Complete the arguments for model.fit() You should now be able to train your model!\n",
    "hist = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show our loss + validation loss (should be decreasing)\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show our accuracy (should be increasing)\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Throw in our own image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put an image of a fruit into the local directory, and replace 'pomelo.png' with the file name\n",
    "\n",
    "# The colors here will probably show up unexpected. This is because cv2 uses G, B, R instead of R, G, B...\n",
    "# Let's fix that in the next cell\n",
    "import cv2\n",
    "img = cv2.imread('pomelo.png')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the image\n",
    "resize = tf.image.resize(img, (100, 100))\n",
    "\n",
    "# Convert GBR to RGB by reordering the channels\n",
    "resize_rgb = tf.reverse(resize, axis=[-1])\n",
    "\n",
    "# Display the corrected RGB image\n",
    "plt.imshow(resize_rgb.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Predict our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following line just wraps our image in another set of parenthesis\n",
    "# This allows the argmax call to work\n",
    "np.expand_dims(resize_rgb, 0).shape\n",
    "yhat = model.predict(np.expand_dims(resize_rgb/255, 0))\n",
    "\n",
    "# This takes the argmax (shows us our predicted class)\n",
    "predicted_class_index = np.argmax(yhat[0])\n",
    "print(predicted_class_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, we want more than just the class number... we want its name so we can use it in the API!\n",
    "\n",
    "# This is the (kind of) gross and inefficient way we found of doing it...\n",
    "# Feel free to implement this differently if you like- perhaps by outputting the dictionary then hardcoding it\n",
    "\n",
    "# TODO: Replace \"Test\" with the name of your testing or training directory\n",
    "\n",
    "# Goes thorugh your directory, sorts each name alphabetically.\n",
    "# Tensorflow will sort your directory alphabetically, so this match names to the previous cell's number\n",
    "directory_names = sorted([name for name in os.listdir(\"Test\") if os.path.isdir(os.path.join(\"Test\", name))])\n",
    "\n",
    "fruits_dict = {}\n",
    "\n",
    "for index, name in enumerate(directory_names):\n",
    "    fruits_dict.update({index: name})\n",
    "\n",
    "fruit = fruits_dict[predicted_class_index]\n",
    "\n",
    "print(fruit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Save the Model\n",
    "So we can later use it in our API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Save the model and put it into a file called fruitclassifier.keras\n",
    "# After running this cell, you should have a black-box like predictor file!\n",
    "model.save('fruitclassifier.keras')\n",
    "new_model = load_model('fruitclassifier.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
